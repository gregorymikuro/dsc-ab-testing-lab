{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing\n",
    "\n",
    "## Introduction\n",
    "\n",
    "A/B testing is a powerful technique for comparing two versions of something (e.g., website layouts, email templates, product features) to see which one performs better based on a specific metric.  This lab will guide you through the process of designing and conducting an A/B test.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "By the end of this lab, you'll be able to:\n",
    "\n",
    "1. List the steps required to design, structure, and run an A/B test (covered in the upcoming steps).\n",
    "2. Choose a metric to measure the success of your A/B test (covered in the next section).\n",
    "\n",
    "## Choosing a Metric\n",
    "\n",
    "The first step in designing an A/B test is selecting a relevant metric to measure its success. This metric should directly reflect the goal of your test. Here are some common A/B testing metrics:\n",
    "\n",
    "* Conversion rate: The percentage of visitors who take a desired action (e.g., purchase a product, sign up for a newsletter).\n",
    "* Click-through rate (CTR): The percentage of visitors who click on a specific link or button.\n",
    "* Engagement time: The average amount of time visitors spend on a webpage or app.\n",
    "* Bounce rate: The percentage of visitors who leave a webpage after viewing only one page.\n",
    "\n",
    "### Code Example (Simulating Website Visitor Behavior):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion Rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define functions for visitor behavior (replace these with your specific actions)\n",
    "def clicks_banner(visitor_id):\n",
    "  # Simulate a random chance of clicking a banner ad (replace with your conversion logic)\n",
    "  return random.random() < 0.1  # 10% chance of clicking\n",
    "\n",
    "def purchases_product(visitor_id):\n",
    "  # Simulate a random chance of purchasing a product (replace with your conversion logic)\n",
    "  return random.random() < 0.05  # 5% chance of purchasing\n",
    "\n",
    "# Simulate 100 website visitors\n",
    "visitors = [100]\n",
    "\n",
    "# Track clicks and purchases for each visitor (replace these with your actual tracking logic)\n",
    "clicks = [clicks_banner(v) for v in visitors]\n",
    "purchases = [purchases_product(v) for v in visitors]\n",
    "\n",
    "# Calculate conversion rate (assuming conversion is a purchase)\n",
    "conversion_rate = sum(purchases) / len(visitors)\n",
    "print(\"Conversion Rate:\", conversion_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Null Hypothesis (H_0)\n",
    "\n",
    "The null hypothesis (H_0) represents the status quo, the idea you're trying to disprove in the A/B test.  For instance, you might hypothesize that there's no difference in conversion rate between two website layouts (A and B). Here's how to formulate the null hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H_0: The conversion rate for website layout A is equal to the conversion rate for website layout B.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating the Alternative Hypothesis (H_1)\n",
    "\n",
    "The alternative hypothesis (H_1) is the opposite of the null hypothesis. It's the scenario you're hoping to prove true.  Here, you might hypothesize that website layout A has a higher conversion rate compared to B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H_1: The conversion rate for website layout A is greater than the conversion rate for website layout B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Alpha (α), Power (β), Effect Size, and Sample Size\n",
    "\n",
    "Before running the A/B test, we need to consider several factors:\n",
    "\n",
    "* Alpha (α): This is the probability of committing a Type I error (false positive), which means rejecting the null hypothesis when it's actually true. A common standard for alpha is 0.05 (5% chance).\n",
    "\n",
    "* Power (β): This is the probability of avoiding a Type II error (false negative), which means failing to reject the null hypothesis when it's actually false. A good practice is to aim for a high power, such as 0.8 (80% chance of detecting a true difference).\n",
    "\n",
    "* Effect Size: This represents the magnitude of the difference you're trying to detect between the two versions being tested. A larger effect size is easier to detect with a smaller sample size.\n",
    "\n",
    "* Sample Size: This is the number of participants needed in your A/B test to achieve a desired level of power and alpha. There's a trade-off between sample size and cost/feasibility.\n",
    "\n",
    "### Code Example (Power Analysis using Statsmodels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "# Example parameters (replace these with your values)\n",
    "alpha = 0.05  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this introduction to A/B testing, we've explored the key steps involved in designing and conducting a successful experiment. We covered the importance of choosing a relevant metric to measure success, and how to formulate the null and alternative hypotheses to frame your test. We then delved into the crucial factors of alpha (α), power (β), effect size, and sample size, highlighting the need to balance statistical rigor with practical feasibility.\n",
    "\n",
    "By understanding these concepts and utilizing tools like power analysis, you can design A/B tests that deliver valuable insights for optimizing your websites, applications, or marketing campaigns. The upcoming labs will provide opportunities to apply these concepts and refine your A/B testing skills through practical scenarios.\n",
    "\n",
    "Remember: A/B testing is an iterative process. As you gather data and refine your understanding, you can continuously improve your testing methodology and gain a data-driven edge in achieving your goals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
